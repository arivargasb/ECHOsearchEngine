{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Create-a-super-smart-search-engine-over-any-free-text-data-source\" data-toc-modified-id=\"Create-a-super-smart-search-engine-over-any-free-text-data-source-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Create a super smart search engine over any free text data source</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Load-data-and-create-DF\" data-toc-modified-id=\"Load-data-and-create-DF-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Load data and create DF</a></span></li><li><span><a href=\"#Preprocess-and-tokenise\" data-toc-modified-id=\"Preprocess-and-tokenise-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Preprocess and tokenise</a></span></li><li><span><a href=\"#Fast-text\" data-toc-modified-id=\"Fast-text-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Fast text</a></span></li><li><span><a href=\"#Load-fasttext-and-query\" data-toc-modified-id=\"Load-fasttext-and-query-1.0.4\"><span class=\"toc-item-num\">1.0.4&nbsp;&nbsp;</span>Load fasttext and query</a></span></li><li><span><a href=\"#Creating-BM25-document-vectors:\" data-toc-modified-id=\"Creating-BM25-document-vectors:-1.0.5\"><span class=\"toc-item-num\">1.0.5&nbsp;&nbsp;</span>Creating BM25 document vectors:</a></span></li><li><span><a href=\"#Load-document-vectors,-build-index-and-search:\" data-toc-modified-id=\"Load-document-vectors,-build-index-and-search:-1.0.6\"><span class=\"toc-item-num\">1.0.6&nbsp;&nbsp;</span>Load document vectors, build index and search:</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWgIO442deb4"
   },
   "source": [
    "# Create a super smart search engine over any free text data source\n",
    "\n",
    "This code acompanies the following blog posts by https://medium.com/@thejoshtaylor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "RBXVOmHPU7BZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariadnavargas/anaconda3/lib/python3.7/site-packages/google/colab/data_table.py:30: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  from IPython.utils import traitlets as _traitlets\n",
      "/Users/ariadnavargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.fasttext import FastText\n",
    "# !pip install rank_bm25 --quiet #install BM25\n",
    "# !pip install --no-binary :all: nmslib #install nmslib\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nmslib\n",
    "import time\n",
    "from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive') # if you want to use G Drive\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6F6jJqPA4Wm"
   },
   "source": [
    "### Load data and create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "v1z4PTE_l9aE",
    "outputId": "2387aa03-949e-4556-ed2a-5da501b79633"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212447, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LINK TO DATASET USED:\n",
    "# https://drive.google.com/file/d/13LLeNj9Fajk0PBd7U5kXEhsEpSRMWwbJ/view?usp=sharing\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/export.csv')\n",
    "df['text'] = df['tendertitle'] + ' ' + df['tenderdescription']+ ' ' + df['locality']+ ' ' + df['postalCode']\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "id": "krRfSYDew1_D",
    "outputId": "b6c301ae-aafb-479c-d1b9-87640e59821f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>externalid</th>\n",
       "      <th>tendertitle</th>\n",
       "      <th>tenderdescription</th>\n",
       "      <th>locality</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00227ecd-50ac-4f92-9e7f-d2675663efa2</td>\n",
       "      <td>TELEPHONY SERVICES</td>\n",
       "      <td>TELEPHONY SERVICES</td>\n",
       "      <td>Exeter</td>\n",
       "      <td>EX1 3PB</td>\n",
       "      <td>TELEPHONY SERVICES TELEPHONY SERVICES Exeter EX1 3PB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             externalid         tendertitle  \\\n",
       "0  00227ecd-50ac-4f92-9e7f-d2675663efa2  TELEPHONY SERVICES   \n",
       "\n",
       "    tenderdescription locality postalCode  \\\n",
       "0  TELEPHONY SERVICES  Exeter   EX1 3PB     \n",
       "\n",
       "                                                   text  \n",
       "0  TELEPHONY SERVICES TELEPHONY SERVICES Exeter EX1 3PB  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfQKWB20A7_C"
   },
   "source": [
    "### Preprocess and tokenise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "id": "Bdqu_tJFBD_c",
    "outputId": "2d0429af-20c6-467f-b716-41aaa58fd6b2"
   },
   "outputs": [],
   "source": [
    "import ftfy\n",
    "\n",
    "tokenise and do some cleaning: remove punctuation, white space \n",
    "and convert the text to lowercase\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tok_text=[] # for our tokenised corpus\n",
    "text = df.text.str.lower().values\n",
    "text = [ftfy.fix_text(str(i)) for i in text] # change bad unicode with good unicode\n",
    "\n",
    "#Tokenising using SpaCy:\n",
    "for doc in tqdm(nlp.pipe(text, n_threads=2, disable=[\"tagger\", \"parser\",\"ner\"])):\n",
    "    tok = [t.text for t in doc if (t.is_ascii and not t.is_punct and not t.is_space)]\n",
    "    tok_text.append(tok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQzcxM3xBBw1"
   },
   "source": [
    "### Fast text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MwHKx5fcxq70"
   },
   "outputs": [],
   "source": [
    "# create word vectors with FastText\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "ft_model = FastText(\n",
    "    sg=1, # use skip-gram: usually gives better results\n",
    "    size=100, # embedding dimension (default)\n",
    "    window=10, # window size: 10 tokens before and 10 tokens after to get wider context\n",
    "    min_count=5, # only consider tokens with at least n occurrences in the corpus\n",
    "    negative=15, # negative subsampling: bigger than default to sample negative examples more\n",
    "    min_n=2, # min character n-gram\n",
    "    max_n=5 # max character n-gram\n",
    ")\n",
    "\n",
    "ft_model.build_vocab(tok_text)\n",
    "\n",
    "ft_model.train(\n",
    "    tok_text,\n",
    "    epochs=6,\n",
    "    total_examples=ft_model.corpus_count, \n",
    "    total_words=ft_model.corpus_total_words)\n",
    "\n",
    "ft_model.save('_fasttext.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1ZSQftUqtMP"
   },
   "source": [
    "### Load fasttext and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "NFqKwbjmqvSV",
    "outputId": "263893f2-b16f-4d97-8ef4-3ceac2b7407d"
   },
   "outputs": [],
   "source": [
    "ft_model = FastText.load('_fasttext.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "OLwIfq-bLSCr",
    "outputId": "986d87e5-2c76-4acb-e758-2225038fcebc"
   },
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    pd.DataFrame(ft_model.wv.most_similar(\"m4\", topn=20, restrict_vocab=5000),columns=['Word','Score']).plot.barh(x='Word',figsize=(6,6),color=(0.3,0.7,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "ISuOgynlLe0T",
    "outputId": "51ccf307-376e-4a54-cfca-ffae5d3a292d"
   },
   "outputs": [],
   "source": [
    "with plt.xkcd():\n",
    "    pd.DataFrame(ft_model.wv.most_similar(\"rg9\", topn=10, restrict_vocab=10000),columns=['Word','Score']).plot.barh(x='Word',figsize=(6,6),color=(0.3,0.7,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-qO3nVYKsJt"
   },
   "source": [
    "### Creating BM25 document vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "D58X-5E0sNDa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/ariadnavargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "212447it [02:47, 1267.77it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25 = BM25Okapi(tok_text)\n",
    "weighted_doc_vects = []\n",
    "\n",
    "for i,doc in tqdm(enumerate(tok_text)):\n",
    "    doc_vector = []\n",
    "    for word in doc:\n",
    "        vector = ft_model[word]\n",
    "        weight = (bm25.idf[word] * ((bm25.k1 + 1.0)*bm25.doc_freqs[i][word])) \n",
    "        / \n",
    "        (bm25.k1 * (1.0 - bm25.b + bm25.b *(bm25.doc_len[i]/bm25.avgdl))+bm25.doc_freqs[i][word])\n",
    "        weighted_vector = vector * weight\n",
    "        doc_vector.append(weighted_vector)\n",
    "    doc_vector_mean = np.mean(doc_vector,axis=0)\n",
    "    weighted_doc_vects.append(doc_vector_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zCE4948dvsy6"
   },
   "outputs": [],
   "source": [
    "pickle.dump( weighted_doc_vects, open( \"weighted_doc_vects.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixGcVaAqKxK7"
   },
   "source": [
    "### Load document vectors, build index and search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-60uBQBW19W9"
   },
   "outputs": [],
   "source": [
    "with open( \"weighted_doc_vects.p\", \"rb\" ) as f:\n",
    "    weighted_doc_vects = pickle.load(f)\n",
    "# create a random matrix to index\n",
    "data = np.vstack(weighted_doc_vects)\n",
    "\n",
    "# initialize a new index, using a HNSW index on Cosine Similarity - can take a couple of mins\n",
    "index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "index.addDataPointBatch(data)\n",
    "index.createIndex({'post': 2}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "63qqZjXT3BOH",
    "outputId": "0e5b6695-925b-4f50-8a11-f6ce7f85d3f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searched 212447 records in 0.0066 seconds \n",
      "\n",
      "0.27\n",
      "CYBER SECURITY INFORMED SAFETY CASES CONTRACT FOR CYBER SECURITY INFORMED SAFETY CASES Newport NP10 8QQ\n",
      "0.27\n",
      "PROVISION OF CYBER RESILIENCE COURSE PROVISION OF CYBER RESILIENCE COURSE Glasgow G2 8EX\n",
      "0.28\n",
      "DEFENCE CYBER PROTECTION TOOL (OCTAVIAN) CONTINUATION OF THE SUPPORT/DEVELOPMENT WORK ON THE DEFENCE CYBER PROTECTION TOOL Corsham SN13 9NR\n",
      "0.28\n",
      "DISATER VICTIM IDENTIFICATION SOFTWARE SPECIALIST SOFTWARE FOR IDENTIFICATION OF DISASTER VICTIMS. London SW1 4DF\n",
      "0.28\n",
      "PROVISION OF A DEFENCE INCIDENT MANAGEMENT DATABASE PROVISION OF A DEFENCE INCIDENT MANAGEMENT DATABASE Corsham SN13 9NR\n",
      "0.28\n",
      "TRANSPARENCY NOTICE: PROVISION AND DELIVERY OF CYBER RESILIENCE TRAINING COURSE THE PROVISION AND DELIVERY OF A CYBER RESILIENCE TRAINING COURSE FOR THE MINISTRY OF DEFENCE. Glasgow G2 8EX\n",
      "0.29\n",
      "CAPABILITY DEVELOPMENT IN SUPPORT OF DEFENSIVE CYBER OPERATIONS CAPABILITY DEVELOPMENT IN SUPPORT OF DEFENSIVE CYBER OPERATIONS FOR NAVY COMMAND MARITIME DCO CONCEPT OF EMPLOYMENT Portsmouth PO1 3LU\n",
      "0.29\n",
      "PROVISION OF DEFENSIVE CYBER OPERATIONAL SOFTWARE PROVISION OF DEFENSIVE CYBER OPERATIONAL SOFTWARE WITH SUPPORT AND MAINTENANCE Liverpool L3 9PP\n",
      "0.29\n",
      "CYBER SECURITY RESEARCH AND INCIDENTS PROVISION OF CYBER SECURITY RESEARCH AND INCIDENTS Liverpool L3 9PP\n",
      "0.29\n",
      "OSCTRA_CYBER RISK ASSESSMENT 2019/20 RESEARCH CONTRACT FOR OSCT FOCUSED ON CYBER RISK. London SW1P 4DF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ariadnavargas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# querying the index:\n",
    "input = 'defending'.lower().split()\n",
    "\n",
    "\n",
    "query = [ft_model[vec] for vec in input]\n",
    "query = np.mean(query,axis=0)\n",
    "\n",
    "t0 = time.time()\n",
    "ids, distances = index.knnQuery(query, k=10)\n",
    "t1 = time.time()\n",
    "print(f'Searched {df.shape[0]} records in {round(t1-t0,4) } seconds \\n')\n",
    "for i,j in zip(ids,distances):\n",
    "    print(round(j,2))\n",
    "    print(df.text.values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Smart Search.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
